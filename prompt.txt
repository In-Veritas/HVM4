# UNDUP Optimization for HVM4

TASK:

create an optimization named UNDUP. to do so, we'll add a new global static set
named UNDUP, which will be a set of disabled labels (u24).

before we proceed, let me explain what collapsing, and sup trees, are.

the collapser is a function that takes a term with nested SUP's (&L{x,y}) and
ERA's (&{}), and lifts these SUP's / ERA's up, resulting in a tree of SUP nodes,
where leaves are either ERA's, or terms that don't contain further SUP's or
ERA's. we then flatten that tree, resulting in a stream of SUP/ERA-free terms.

for example, consider:

@main = λf.
  ! f &A = f;
  &A{
    λx.
      ! f &B = f₀;
      ! x &B = x;
      &B{f₀(x₀,0), f₁(x₁,1)},
    λx.
      ! f &C = f₁;
      ! x &C = x;
      &C{f₀(x₀,2), f₁(x₁,3)},
  }

just normalizing this program would give us:

λa.&A{λb.&B{a(b,0),a(b,1)},λb.&C{a(b,2),a(b,3)}}

yet, collapsing it would give us:

&A{&B{λa.λb.a(b,0),λa.λb.a(b,1)},&C{λa.λb.a(b,2),λa.λb.a(b,3)}}

and flattening would give us:

λa.λb.a(b,0)
λa.λb.a(b,1)
λa.λb.a(b,2)
λa.λb.a(b,3)

note that a term is in "collapsed normal form" when it is either a SUP (which
may store terms with further SUPs/ERAs), or an ERA, or a term without SUPs or
ERAs inside it. so, &A{λx.&B{1,2},λy.y} is in collapsed normal form, but
λx.&B{1,2} itself isn't.

now, in order to use the collapser, we must assume that the user respects the
following conventions:

- sup nodes visible to the collapser must have a globally unique label 

- the components of a sup node can't use free 'VAR' vars

- the component 0/1 of a sup node with label L can use 'CO0/1' vars with label L

so, for example, this is valid:

λa. λb.
! A &L = a;
! B &L = b;
&L{ A₀(B₀) , A₁(B₁) }

but this is not:

λa. λb.
! B &L = b;
&L{ a(B₀) , B₁ }

(because 'a' is a free variable used inside the left component of the sup node)

λa. λb.
! A &L = a;
! B &L = b;
&L{ A₁(B₀) , A₀(B₁) }

(because we're using A₁ inside of the side 0; we should use A₀ instead)

now, these assumptions allow us to implement the new optimization, UNDUP.

the idea is to implement a new global static set, named UNDUP, which includes
DUP labels that have been *disabled*. a label is disabled when, during the
flattening, we find a SUP node whose left side collapses to an era.

for example, consider this input:

! X &A = [1,2,3,4,5]
! Y &B = X₁
&A{λx.(λy.&{} 0), &B{Y₀, &{}}}

during flatten, we'd call collapse_step on the left side of the first SUP node.
it would, thus, normalize to weak head normal form (wnf), resulting in:

! X &A = [1,2,3,4,5]
! Y &B = X₁
&A{λx.&{}, &B{Y₀, &{}}}

and then, it would normalize to collapse normal form (cnf), resulting in:

! X &A = [1,2,3,4,5]
! Y &B = X₁
&A{&{}, &B{Y₀, &{}}}

since we've found a SUP node with &{} as the left side of a SUP node, that means
&A must be disabled on the right side of that sup node, i.e., in `&B{Y₀, &{}}`.

when a label is disabled, ALL DUP interactions involving that label are skipped,
meaning that we do NOT perform a copy and, instead, just pass the DUP's value to
the right projection variable (CO1) of that label.

for example, in the case above, when we attempt to wnf:

! X &A = [1,2,3,4,5]

with UNDUP[A] set, we would NOT perform the DUP-CTR interaction (to clone the
#CON{1,[2,3,4]} node of the list). instead, we would skip it, substituting X₀ by
&{}, and X₁ by the whole list.

that is, we would do:

X₀ ← &{}
X₁ ← [1,2,3,4,5]

instead of:

! H &A = 1
! T &A = [2,3,4]
X₀ ← #CON{H₀,T₀}
X₁ ← #CON{H₁,T₁}

this avoids creating additional DUPs, which prevents further DUP-CTR
interactions, reducing the interaction count. that's the optimization!

now, we would then proceed to reduce:

! Y &B = [1,2,3,4,5]
&A{&{}, &B{Y₀, &{}}}

here, the B label is *NOT* disabled (i.e., UNDUP[B] is 0). that's because we
only disable a label when the left side of a node on the SUP tree generated by
the collapser is &{}. in the case above, the right side is &{}, but the
collapser wouldn't even have reached it. as such, we proceed with the DUP-CTR
interactions as normal.

keep in mind that UNDUP is scoped. if we have:

&X{&A{&{}, x}, &A{y, z}}

then, when reducing x, we'd have UNDUP[&A]==1, but, when reducing y and z, we
wouldn't. so, the effect of the UNDUP optimization is to disable DUPs for a
given label L, on the right side of a sup node with label L that has been found,
during the flatten proccess, to have an era node on its left side.

the reason this works is that, whenever we find a &L{&{},X} node, due to the
assumptions we made earlier, all left variables of dups with label L could only
be used on the left side of this sup node, but that side is erased, so, these
variables can't be reached at all. as such, we can just skip these dups, passing
the right side to the right variable, and erasing the left variable.  note that
the collapser reduces from left to right, so, optimizing in the other direction
would be futile. note also that this is nested; if we have &A{&{}, &B{&{}, x}},
then, both A and B will be disabled when collapsing x.

below are some example interactions with the skip optimization on:

! f &L= λx.body; t
------------------------- DUP-LAM
if UNDUP[&L]:
  f₀ ← &{}
  f₁ ← λx.body
  t
else:
  (do as before)

! x &L= &L{a, b}; t
------------------------- DUP-SUP (L = L)
if UNDUP[&L]:
  x₀ ← &{}
  x₁ ← b
  t
else:
  (do as before)

! x &L= &R{a, b}; t
------------------------- DUP-SUP (L ≠ R)
if UNDUP[&L]:
  x₀ ← &{}
  x₁ ← &R{a, b}
  t
else:
  (do as before)


and so on. we must update ALL dup interactions.

if this optimization works, the 4 following tests must pass:


1. undup_simple:

```
@main =
  ! X &A = [1,2,3,4,5];
  &A{ &{} , X₁ }
//[1,2,3,4,5] #<5
```

this ensures the UNDUP array and the interactions are properly set up.

2. undup_cnf

```
@main =
  ! X &A = [1,2,3,4,5];
  &A{ λx.(λy.&{}(0)) , X₁ }
//[1,2,3,4,5] #<5
```

this ensures we're checking if the *cnf* of the left side of a SUP is &{}.

3. undup_equal:

```
@X    = λ&L. &(L){ 0n, 1n+@X(L+1) }
@Y    = λ&f. f(@Y(f))
@when = λ{[]: λx.x; <>: λ{0: λt. &{}; 1: λt,x. @when(t, x)}}
@main = @when([@X(1) === 100n], [@X(1)])
//[100n] #<10000
```

this is a more complex test

4. undup_muln_gen:

```
@Y    = λ&f. f(@Y(f))
@when = λ{[]: λx.x; <>: λ{0: λt. &{}; 1: λt,x. @when(t, x)}}

@muln = λ&L,&K. λF. λ{
  0n: 0n
  1n+: λp. @expr(L, K, F, p)
}
      
@expr = λ&L. λ{
  0n: λf. λx. x;
  1n+: λ&K. λf. λx.
    ! f &(L) = f
    ! x &(L) = x
    &(L){f₀(x₀), 1n+@expr(L+1,K,f₁,x₁)}
}

@main =
  ! &F = λF. @muln(1, 100n, F)
  ! e0 = @Y(F)(3n) === 60n
  ! e1 = @Y(F)(4n) === 80n
  @when([e0,e1], [F])
//[λa.λ{0n:0n;1n+:λb.20n+a(b)}] #<10000
```

5. undup_bin_add:

```
@when = λ{[]: λx.x; <>: λ{0: λt. &{}; 1: λt,x. @when(t, x)}}
@Y    = λ&f. f(@Y(f))

@O = λx.#O{x}
@I = λx.#I{x}
@E = #E

@add = λ&add. λ{
  #O: λ&a. λ{
    #O: λ&b. λ{
      0: &A{@O,@I}(add(a,b,&B{0,1}))
      1: &C{@O,@I}(add(a,b,&D{0,1}))
    }
    #I: λ&b. λ{
      0: &E{@O,@I}(add(a,b,&F{0,1}))
      1: &G{@O,@I}(add(a,b,&H{0,1}))
    }
    #E: λc. #E
  }
  #I: λ&a. λ{
    #O: λ&b. λ{
      0: &I{@O,@I}(add(a,b,&J{0,1}))
      1: &K{@O,@I}(add(a,b,&L{0,1}))
    }
    #I: λ&b. λ{
      0: &M{@O,@I}(add(a,b,&N{0,1}))
      1: &O{@O,@I}(add(a,b,&P{0,1}))
    }
    #E: λc. #E
  }
  #E: λb. λc. #E
}

@main =
  ! e0 = @Y(@add)(@I(@O(@O(@O(@E)))), @O(@I(@O(@O(@E)))), 0) === @I(@I(@O(@O(@E)))) //  1 + 2 =  3
  ! e1 = @Y(@add)(@O(@O(@I(@O(@E)))), @I(@O(@O(@O(@E)))), 0) === @I(@O(@I(@O(@E)))) //  4 + 1 =  5
  ! e2 = @Y(@add)(@I(@I(@I(@O(@E)))), @I(@O(@I(@O(@E)))), 0) === @O(@O(@I(@I(@E)))) //  7 + 5 = 12
  ! e3 = @Y(@add)(@I(@O(@O(@I(@E)))), @O(@O(@I(@O(@E)))), 0) === @I(@O(@I(@I(@E)))) //  9 + 4 = 13
  ! e4 = @Y(@add)(@I(@I(@O(@O(@E)))), @I(@O(@O(@O(@E)))), 0) === @O(@O(@I(@O(@E)))) //  3 + 1 =  4
  ! e5 = @Y(@add)(@I(@I(@O(@I(@E)))), @O(@O(@I(@O(@E)))), 0) === @I(@I(@I(@I(@E)))) // 11 + 4 = 15
  ! e6 = @Y(@add)(@O(@O(@O(@I(@E)))), @I(@I(@O(@O(@E)))), 0) === @I(@I(@O(@I(@E)))) //  8 + 3 = 11
  ! e7 = @Y(@add)(@O(@I(@O(@I(@E)))), @O(@I(@I(@O(@E)))), 0) === @O(@O(@O(@O(@E)))) // 10 + 6 = 16 (overflow wraps)
  @when([e0,e1,e2,e3,e4,e5,e6,e7], @add)
//λa.λ{#O:λb.λ{#O:λc.λ{0:#O{a(b,c,0)};1:#I{a(b,c,0)}};#I:λc.λ{0:#I{a(b,c,0)};1:#O{a(b,c,1)}};#E:λc.#E{}};#I:λb.λ{#O:λc.λ{0:#I{a(b,c,0)};1:#O{a(b,c,1)}};#I:λc.λ{0:#O{a(b,c,1)};1:#I{a(b,c,1)}};#E:λc.#E{}};#E:λb.λc.#E{}} #<10000
```

note that we also add a new test functionality: if the line ends with "
#<NUMBER", the test must also pass with < NUMBER interactions.

your implementation is a success if the new 5 tests pass. some of the current
tests involving sups/collapsing might break (because they aren't respecting the
assumptions outlined above). don't worry, I'll review them manually later. all
old test not involving sups/collapsing must still pass, though.

NOTE: while doing this, do NOT recompile / modify ./clang/main in any way. IT IS
CURRENTLY BEING USED BY ANOTHER PROCESS. use ./clang/main_undup instead to test.
